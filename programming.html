<!DOCTYPE html>
<html>

<head>
	<title>Programming</title>
	<link href="stylesheet.css" rel="stylesheet" type="text/css" />
	<link href="/img/logo.png" rel="shortcut icon" type="image/x-icon" />
</head>
<body>
	<div class="header">
		<div>
			<a href="/"><img src="/img/logo.png" width="100px" height="100px" Title="Home"/></a>
		</div>
		<div>
			<a href="/resources/resume-mark_peng.pdf" target="_blank">Resume</a>
		</div>
		<div>
			<a href="/research.html">Research</a>
		</div>
	</div>
	<div class="main-container">
		<div class="item">
			<div class="icon">
				<a href="http://markvpeng.com/bpm-playlists" target="_blank">
					<img src="/img/spotify.png" Title="demo" />
				</a>
			</div>
			<div class="desc">
				<b>Spotify BPM Playlist Creator</b> (2016)
				<p>A Django web app that uses the Spotify API to create playlists with songs from a user's saved tracks with a specified beats-per-minute range.</p>
				<a href="https://github.com/mvpeng/bpm-playlists" target="_blank">source</a>
			</div>
		</div>
		<div class="item">
			<div class="icon">
				<a href="http://arxiv.org/abs/1503.02230" target="_blank">
					<img src="/img/victory.png" Title="Link to publication" />
				</a>
			</div>
			<div class="desc">
				<b>Machine Learning on League of Legends Data</b> (2014)
				<p>For CS229, Andrew Ng's popular course on machine learning, my teammates and I decided to use machine learning algorithms on League of Legends data to see if we could use team compositions to accurately predict the outcome of a match. Our final product predicted with 70% accuracy the outcome of LoL matches using clustering and classification algorithms on data from 130k matches obtained through the LoL API.
				</p>
				<a href="/resources/ml-lol-poster.pdf" target="_blank">poster</a>
			</div>
		</div>
		<div class="item">
			<div class="icon">
				<a href="http://vhil.stanford.edu/" target="_blank">
					<img src="/img/stanford.png" Title="vhil.stanford.edu" />
				</a>
			</div>
			<div class="desc">
				<b>Stanford Virtual Human Interaction Lab (VHIL)</b> (2013 - 2014)
				<p>Undergraduate programmer in VHIL. I built virtual worlds using Unity and Vizard for use in psychology and sociology experiments as well as lab demos. I also implemented any data analysis scripts that lab researchers needed. This included Python scripts that parsed through gigabytes of positional/rotational data to compute statistics on subjects' movements in a virtual classroom.</p>
			</div>
		</div>
		<div class="item">
			<div class="icon">
				<a href="/resources/kinect.pdf" target="_blank">
					<img src="/img/kinect.png" Title="kinect.pdf" />
				</a>
			</div>
			<div class="desc">
				<b>Using Microsoft's Kinect to Generate 3D Object Overlays</b> (2013)
				<p>For the final project of CS231A, a graduate course on computer vision, my teammate and I attempted to use the Microsoft Kinect to create 3D visual effects similar to those that users can play with in Google Hangouts. Google's Effects uses your webcam to track your face in two dimensions and then overlays 2D objects onto your head/face. Our goal was to use the Kinect to track users in three dimensions and then use the depth data to render a 3D object overlay. The result of the project was that we were able to render a 2D birthday hat over our heads that rotated in all three dimensions as we moved around on camera. Our professor ended up nominating our project as one of the best in class!</p>
			</div>
		</div>
		<div class="item">
			<div class="icon">
				<a href="/resources/piano-fingering.pdf" target="_blank">
					<img src="/img/fingering.png" Title="piano-fingering.pdf" />
				</a>
			</div>
			<div class="desc">
				<b>Piano Fingering Generation with Linear CRFs</b> (2013)
				<p>For my artifical intelligence class, CS221, my teammate and I decided to build a system that would take in unfingered sequences of notes and generate fingerings for those notes. The idea was that this system could be used to help beginner piano students learn to play a new piece of music. We decided to use a variable-based model, specifically a chain-structure factor graph called a linear-chain conditional random field (CRF). Our finished system generated physically possible sets of fingerings that were comparable to professionally determined fingerings.</p>
			</div>
		</div>
		<div class="item">
			<div class="icon">
				<a href="http://www.highfidelity.io" target="_blank">
					<img src="/img/hifi.png" height="100px" Title="highfidelity.io" />
				</a>
			</div>
			<div class="desc">
				<b>High Fidelity</b> (2013)
				<p>Software engineering intern in High Fidelity's (HiFi's) first intern class. I had fun playing with a lot of toys, like the Leap Motion, Oculus Rift, and PrimeSense depth cams, and attempted to integrate them into part of an immersive reality experience. I worked largely in C++ (with OpenNI, OpenGL, and Qt) and got a taste of dealing with graphics/physics in 3D.</p>
			</div>
		</div>
	</div>
</body>

</html>